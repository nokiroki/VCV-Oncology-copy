{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "melanoma-pytorch-starter.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fbff4ae174a045f8b084df0fa1e84228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba200f6d76714fdb8030bdc6257af9df",
              "IPY_MODEL_9f0e5117a0df4b2aac44106b0957cd76",
              "IPY_MODEL_7a367f03ffcd48e0930b580609e86eb7"
            ],
            "layout": "IPY_MODEL_b4b7374aec444e6dbb590ef3f20b3213"
          }
        },
        "ba200f6d76714fdb8030bdc6257af9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9186c15080034c1b8a4d3aebc45ae3f9",
            "placeholder": "​",
            "style": "IPY_MODEL_69695c9a31c046d294ed275946cb6dcb",
            "value": "100%"
          }
        },
        "9f0e5117a0df4b2aac44106b0957cd76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e9cd363df8b4d83ab9de1a6cf064208",
            "max": 31519111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3df4c5f984944fcd871a209227ee82cd",
            "value": 31519111
          }
        },
        "7a367f03ffcd48e0930b580609e86eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29b9952f45144fd856156063094fe37",
            "placeholder": "​",
            "style": "IPY_MODEL_9ab7939445934eeb8a2024b4a72eb437",
            "value": " 30.1M/30.1M [00:00&lt;00:00, 126MB/s]"
          }
        },
        "b4b7374aec444e6dbb590ef3f20b3213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9186c15080034c1b8a4d3aebc45ae3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69695c9a31c046d294ed275946cb6dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e9cd363df8b4d83ab9de1a6cf064208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df4c5f984944fcd871a209227ee82cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b29b9952f45144fd856156063094fe37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab7939445934eeb8a2024b4a72eb437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olegrgv/VCV-Oncology/blob/main/Vsevolod/melanoma_pytorch_starter_efficientnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Versions:\n",
        "* v9: ColorJitter transformation added **[0.896]**\n",
        "* v10: Changed the dataset to [this one](https://www.kaggle.com/shonenkov/melanoma-merged-external-data-512x512-jpeg) with external data. **[0.894]**\n",
        "* v11: Switched to [another dataset](https://www.kaggle.com/nroman/melanoma-external-malignant-256/) which I've created by myself. Also switched from StratifiedKFold to GroupKFold **[0.916]**\n",
        "* v12: Switched to efficientnet-b1 **[0.919]**\n",
        "* v13: Using meta featues: sex and age **[0.918]**\n",
        "* v14: anatom_site_general_challenge meta feature added as one-hot encoded matrix **[0.923]**\n",
        "* v16: Fixed OOF - now it contains only data from original training dataset, without extarnal data. Also switched back to StratifiedKFold. Added DrawHair augmentation. **[0.909]**\n",
        "* v18: Too many things were changed at the same time. All experiments should have only one small change each, so it would be easy to understand how changes affect the result. Said that I rolled back everything, keeping only OOF fix, to make sure it work.\n",
        "* v19: Added 'Hair' augmentation. OOF rework posponed untill the best time, since there is some bug in my code for it. **[0.925]**\n",
        "* v20: Advanced Hair Augmentation technique used. Read more about it here: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/159176 **[0.923]**\n",
        "* v21: Microscope augmentation added instead of Cutout. Read more here: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/159476 **[0.914]**\n",
        "* v22: Changed the dataset to [this one](https://www.kaggle.com/cdeotte/jpeg-melanoma-256x256) by Chris Deotte. More info [here](https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/165526) **[0.900]**\n",
        "* v23: All the same as v22 but effnet-b0 instead of b1 and more epochs per fold. **[0.895]**\n",
        "* v24: effnet-b01 and more epochs. **[0.9092]**\n",
        "* v25: Fixed a mistake in a way of filling preds. See [this comment](https://www.kaggle.com/nroman/melanoma-pytorch-starter-efficientnet/comments?scriptVersionId=39125585#913846). **[0.9016]**\n",
        "* v26: Fix for another mistake. This time with a way of averaging TTA. See [this comment](https://www.kaggle.com/nroman/melanoma-pytorch-starter-efficientnet/comments#955916) **[0.915]**\n",
        "* v27: Back to [my dataset](https://www.kaggle.com/nroman/melanoma-external-malignant-256/)"
      ],
      "metadata": {
        "id": "iBb3uNh4CFFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "l7ElkfhbCIM4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload() # upload kaggle.json\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "hX-qTgZRCsWR",
        "outputId": "68c2f48a-8961-461e-d713-ec9b0c5dc2a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4df438b7-c7b1-410b-9180-499481d37210\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4df438b7-c7b1-410b-9180-499481d37210\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload();"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Rjl8IWEMIgvU",
        "outputId": "e85c1329-5509-4b08-e4d9-8200cbb6ca21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1e3a0834-544a-46c4-8011-ebefa5cf336e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1e3a0834-544a-46c4-8011-ebefa5cf336e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample_submission.csv to sample_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folders = ['jpeg-melanoma-256x256', 'melanoma-hairs', 'melanoma-external-malignant-256']\n",
        "dataset_locations = ['cdeotte/jpeg-melanoma-256x256', 'nroman/melanoma-hairs', 'nroman/melanoma-external-malignant-256']\n",
        "for dataset_folder, dataset_location in zip(dataset_folders, dataset_locations):\n",
        "    ! kaggle datasets download -d {dataset_location}\n",
        "    ! mkdir {dataset_folder}\n",
        "    ! unzip -q {dataset_folder} -d {dataset_folder}\n",
        "    ! rm {dataset_folder}.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEvjdN0JEWNx",
        "outputId": "d339e90d-2736-4ecd-a1ec-bf528f11e02c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading jpeg-melanoma-256x256.zip to /content\n",
            " 98% 775M/791M [00:06<00:00, 155MB/s]\n",
            "100% 791M/791M [00:06<00:00, 127MB/s]\n",
            "Downloading melanoma-hairs.zip to /content\n",
            "  0% 0.00/26.2k [00:00<?, ?B/s]\n",
            "100% 26.2k/26.2k [00:00<00:00, 21.6MB/s]\n",
            "Downloading melanoma-external-malignant-256.zip to /content\n",
            "100% 1.01G/1.01G [00:07<00:00, 140MB/s]\n",
            "100% 1.01G/1.01G [00:07<00:00, 147MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install efficientnet_pytorch torchtoolbox"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-06-17T04:07:56.180661Z",
          "iopub.execute_input": "2022-06-17T04:07:56.180984Z",
          "iopub.status.idle": "2022-06-17T04:08:20.700525Z",
          "shell.execute_reply.started": "2022-06-17T04:07:56.180954Z",
          "shell.execute_reply": "2022-06-17T04:08:20.699492Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kioNt7tUCFFJ",
        "outputId": "b422b924-7f6a-4c08-c90c-3fe7c3e6dc36"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 84 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 32.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 45.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.6 MB/s \n",
            "\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchtoolbox.transform as transforms\n",
        "# import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import datetime\n",
        "import warnings\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-06-17T04:08:31.331588Z",
          "iopub.execute_input": "2022-06-17T04:08:31.331886Z",
          "iopub.status.idle": "2022-06-17T04:08:34.676049Z",
          "shell.execute_reply.started": "2022-06-17T04:08:31.331856Z",
          "shell.execute_reply": "2022-06-17T04:08:34.674837Z"
        },
        "trusted": true,
        "id": "XFtSpxU0CFFL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.simplefilter('ignore')\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(47)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:08:34.681366Z",
          "iopub.execute_input": "2022-06-17T04:08:34.684023Z",
          "iopub.status.idle": "2022-06-17T04:08:34.698479Z",
          "shell.execute_reply.started": "2022-06-17T04:08:34.683975Z",
          "shell.execute_reply": "2022-06-17T04:08:34.697307Z"
        },
        "trusted": true,
        "id": "i_0GFZUKCFFM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:08:34.705822Z",
          "iopub.execute_input": "2022-06-17T04:08:34.708514Z",
          "iopub.status.idle": "2022-06-17T04:08:34.745260Z",
          "shell.execute_reply.started": "2022-06-17T04:08:34.708469Z",
          "shell.execute_reply": "2022-06-17T04:08:34.743858Z"
        },
        "trusted": true,
        "id": "0aRrOPguCFFM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MelanomaDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, imfolder: str, train: bool = True, transforms = None, meta_features = None):\n",
        "        \"\"\"\n",
        "        Class initialization\n",
        "        Args:\n",
        "            df (pd.DataFrame): DataFrame with data description\n",
        "            imfolder (str): folder with images\n",
        "            train (bool): flag of whether a training dataset is being initialized or testing one\n",
        "            transforms: image transformation method to be applied\n",
        "            meta_features (list): list of features with meta information, such as sex and age\n",
        "            \n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.imfolder = imfolder\n",
        "        self.transforms = transforms\n",
        "        self.train = train\n",
        "        self.meta_features = meta_features\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        im_path = os.path.join(self.imfolder, self.df.iloc[index]['image_name'] + '.jpg')\n",
        "        x = cv2.imread(im_path)\n",
        "        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n",
        "\n",
        "        if self.transforms:\n",
        "            x = self.transforms(x)\n",
        "            \n",
        "        if self.train:\n",
        "            y = self.df.iloc[index]['target']\n",
        "            return (x, meta), y\n",
        "        else:\n",
        "            return (x, meta)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    \n",
        "class Net(nn.Module):\n",
        "    def __init__(self, arch, n_meta_features: int):\n",
        "        super(Net, self).__init__()\n",
        "        self.arch = arch\n",
        "        if 'ResNet' in str(arch.__class__):\n",
        "            self.arch.fc = nn.Linear(in_features=512, out_features=500, bias=True)\n",
        "        if 'EfficientNet' in str(arch.__class__):\n",
        "            self.arch._fc = nn.Linear(in_features=1280, out_features=500, bias=True)\n",
        "        self.meta = nn.Sequential(nn.Linear(n_meta_features, 500),\n",
        "                                  nn.BatchNorm1d(500),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(p=0.2),\n",
        "                                  nn.Linear(500, 250),  # FC layer output will have 250 features\n",
        "                                  nn.BatchNorm1d(250),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(p=0.2))\n",
        "        self.ouput = nn.Linear(500 + 250, 1)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
        "        Which applies sigmoid for us when calculating a loss\n",
        "        \"\"\"\n",
        "        x, meta = inputs\n",
        "        cnn_features = self.arch(x)\n",
        "        meta_features = self.meta(meta)\n",
        "        features = torch.cat((cnn_features, meta_features), dim=1)\n",
        "        output = self.ouput(features)\n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:08:34.751155Z",
          "iopub.execute_input": "2022-06-17T04:08:34.754225Z",
          "iopub.status.idle": "2022-06-17T04:08:34.785689Z",
          "shell.execute_reply.started": "2022-06-17T04:08:34.754176Z",
          "shell.execute_reply": "2022-06-17T04:08:34.784417Z"
        },
        "trusted": true,
        "id": "scbnRMg_CFFN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedHairAugmentation:\n",
        "    \"\"\"\n",
        "    Impose an image of a hair to the target image\n",
        "\n",
        "    Args:\n",
        "        hairs (int): maximum number of hairs to impose\n",
        "        hairs_folder (str): path to the folder with hairs images\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hairs: int = 5, hairs_folder: str = \"\"):\n",
        "        self.hairs = hairs\n",
        "        self.hairs_folder = hairs_folder\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (PIL Image): Image to draw hairs on.\n",
        "\n",
        "        Returns:\n",
        "            PIL Image: Image with drawn hairs.\n",
        "        \"\"\"\n",
        "        n_hairs = random.randint(0, self.hairs)\n",
        "        \n",
        "        if not n_hairs:\n",
        "            return img\n",
        "        \n",
        "        height, width, _ = img.shape  # target image width and height\n",
        "        hair_images = [im for im in os.listdir(self.hairs_folder) if 'png' in im]\n",
        "        \n",
        "        for _ in range(n_hairs):\n",
        "            hair = cv2.imread(os.path.join(self.hairs_folder, random.choice(hair_images)))\n",
        "            hair = cv2.flip(hair, random.choice([-1, 0, 1]))\n",
        "            hair = cv2.rotate(hair, random.choice([0, 1, 2]))\n",
        "\n",
        "            h_height, h_width, _ = hair.shape  # hair image width and height\n",
        "            roi_ho = random.randint(0, img.shape[0] - hair.shape[0])\n",
        "            roi_wo = random.randint(0, img.shape[1] - hair.shape[1])\n",
        "            roi = img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width]\n",
        "\n",
        "            # Creating a mask and inverse mask\n",
        "            img2gray = cv2.cvtColor(hair, cv2.COLOR_BGR2GRAY)\n",
        "            ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
        "            mask_inv = cv2.bitwise_not(mask)\n",
        "\n",
        "            # Now black-out the area of hair in ROI\n",
        "            img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
        "\n",
        "            # Take only region of hair from hair image.\n",
        "            hair_fg = cv2.bitwise_and(hair, hair, mask=mask)\n",
        "\n",
        "            # Put hair in ROI and modify the target image\n",
        "            dst = cv2.add(img_bg, hair_fg)\n",
        "\n",
        "            img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width] = dst\n",
        "                \n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}(hairs={self.hairs}, hairs_folder=\"{self.hairs_folder}\")'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:08:34.791184Z",
          "iopub.execute_input": "2022-06-17T04:08:34.794586Z",
          "iopub.status.idle": "2022-06-17T04:08:34.822008Z",
          "shell.execute_reply.started": "2022-06-17T04:08:34.794538Z",
          "shell.execute_reply": "2022-06-17T04:08:34.820883Z"
        },
        "trusted": true,
        "id": "Iu4oSQSyCFFO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DrawHair:\n",
        "    \"\"\"\n",
        "    Draw a random number of pseudo hairs\n",
        "\n",
        "    Args:\n",
        "        hairs (int): maximum number of hairs to draw\n",
        "        width (tuple): possible width of the hair in pixels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hairs:int = 4, width:tuple = (1, 2)):\n",
        "        self.hairs = hairs\n",
        "        self.width = width\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (PIL Image): Image to draw hairs on.\n",
        "\n",
        "        Returns:\n",
        "            PIL Image: Image with drawn hairs.\n",
        "        \"\"\"\n",
        "        if not self.hairs:\n",
        "            return img\n",
        "        \n",
        "        width, height, _ = img.shape\n",
        "        \n",
        "        for _ in range(random.randint(0, self.hairs)):\n",
        "            # The origin point of the line will always be at the top half of the image\n",
        "            origin = (random.randint(0, width), random.randint(0, height // 2))\n",
        "            # The end of the line \n",
        "            end = (random.randint(0, width), random.randint(0, height))\n",
        "            color = (0, 0, 0)  # color of the hair. Black.\n",
        "            cv2.line(img, origin, end, color, random.randint(self.width[0], self.width[1]))\n",
        "        \n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}(hairs={self.hairs}, width={self.width})'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:08:34.826193Z",
          "iopub.execute_input": "2022-06-17T04:08:34.826775Z",
          "iopub.status.idle": "2022-06-17T04:08:34.850446Z",
          "shell.execute_reply.started": "2022-06-17T04:08:34.826717Z",
          "shell.execute_reply": "2022-06-17T04:08:34.848739Z"
        },
        "trusted": true,
        "id": "Fp-gIcdPCFFQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Microscope:\n",
        "    \"\"\"\n",
        "    Cutting out the edges around the center circle of the image\n",
        "    Imitating a picture, taken through the microscope\n",
        "\n",
        "    Args:\n",
        "        p (float): probability of applying an augmentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p: float = 0.5):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (PIL Image): Image to apply transformation to.\n",
        "\n",
        "        Returns:\n",
        "            PIL Image: Image with transformation.\n",
        "        \"\"\"\n",
        "        if random.random() < self.p:\n",
        "            circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8), # image placeholder\n",
        "                        (img.shape[0]//2, img.shape[1]//2), # center point of circle\n",
        "                        random.randint(img.shape[0]//2 - 3, img.shape[0]//2 + 15), # radius\n",
        "                        (0, 0, 0), # color\n",
        "                        -1)\n",
        "\n",
        "            mask = circle - 255\n",
        "            img = np.multiply(img, mask)\n",
        "        \n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}(p={self.p})'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:08:34.855906Z",
          "iopub.execute_input": "2022-06-17T04:08:34.858849Z",
          "iopub.status.idle": "2022-06-17T04:08:34.874502Z",
          "shell.execute_reply.started": "2022-06-17T04:08:34.858802Z",
          "shell.execute_reply": "2022-06-17T04:08:34.873158Z"
        },
        "trusted": true,
        "id": "5riHjWGtCFFQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "home='/content/'\n",
        "train_transform = transforms.Compose([\n",
        "    AdvancedHairAugmentation(hairs_folder=home+'melanoma-hairs'),\n",
        "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    Microscope(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:10:06.791526Z",
          "iopub.execute_input": "2022-06-17T04:10:06.791905Z",
          "iopub.status.idle": "2022-06-17T04:10:06.801155Z",
          "shell.execute_reply.started": "2022-06-17T04:10:06.791872Z",
          "shell.execute_reply": "2022-06-17T04:10:06.799871Z"
        },
        "trusted": true,
        "id": "tJ2Y2EpVCFFR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arch = EfficientNet.from_pretrained('efficientnet-b1')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:09:07.244044Z",
          "iopub.execute_input": "2022-06-17T04:09:07.244452Z",
          "iopub.status.idle": "2022-06-17T04:09:09.445052Z",
          "shell.execute_reply.started": "2022-06-17T04:09:07.244412Z",
          "shell.execute_reply": "2022-06-17T04:09:09.443652Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "fbff4ae174a045f8b084df0fa1e84228",
            "ba200f6d76714fdb8030bdc6257af9df",
            "9f0e5117a0df4b2aac44106b0957cd76",
            "7a367f03ffcd48e0930b580609e86eb7",
            "b4b7374aec444e6dbb590ef3f20b3213",
            "9186c15080034c1b8a4d3aebc45ae3f9",
            "69695c9a31c046d294ed275946cb6dcb",
            "4e9cd363df8b4d83ab9de1a6cf064208",
            "3df4c5f984944fcd871a209227ee82cd",
            "b29b9952f45144fd856156063094fe37",
            "9ab7939445934eeb8a2024b4a72eb437"
          ]
        },
        "id": "ac1oH49-CFFS",
        "outputId": "2d9b5b01-e498-44a5-d106-9e636cf5a327"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b1-f1951068.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/30.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbff4ae174a045f8b084df0fa1e84228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = home+'jpeg-melanoma-256x256/'\n",
        "train_df = pd.read_csv(main_path + 'train.csv')\n",
        "test_df = pd.read_csv(main_path + 'test.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:10:10.220411Z",
          "iopub.execute_input": "2022-06-17T04:10:10.220827Z",
          "iopub.status.idle": "2022-06-17T04:10:10.332841Z",
          "shell.execute_reply.started": "2022-06-17T04:10:10.220792Z",
          "shell.execute_reply": "2022-06-17T04:10:10.331782Z"
        },
        "trusted": true,
        "id": "P5xUhns_CFFT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding of anatom_site_general_challenge feature\n",
        "concat = pd.concat([train_df['anatom_site_general_challenge'], test_df['anatom_site_general_challenge']], ignore_index=True)\n",
        "dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
        "train_df = pd.concat([train_df, dummies.iloc[:train_df.shape[0]]], axis=1)\n",
        "test_df = pd.concat([test_df, dummies.iloc[train_df.shape[0]:].reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Sex features\n",
        "train_df['sex'] = train_df['sex'].map({'male': 1, 'female': 0})\n",
        "test_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\n",
        "train_df['sex'] = train_df['sex'].fillna(-1)\n",
        "test_df['sex'] = test_df['sex'].fillna(-1)\n",
        "\n",
        "# Age features\n",
        "train_df['age_approx'] /= train_df['age_approx'].max()\n",
        "test_df['age_approx'] /= test_df['age_approx'].max()\n",
        "train_df['age_approx'] = train_df['age_approx'].fillna(0)\n",
        "test_df['age_approx'] = test_df['age_approx'].fillna(0)\n",
        "\n",
        "train_df['patient_id'] = train_df['patient_id'].fillna(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:10:10.659613Z",
          "iopub.execute_input": "2022-06-17T04:10:10.660020Z",
          "iopub.status.idle": "2022-06-17T04:10:10.711728Z",
          "shell.execute_reply.started": "2022-06-17T04:10:10.659984Z",
          "shell.execute_reply": "2022-06-17T04:10:10.710523Z"
        },
        "trusted": true,
        "id": "MxWltyWmCFFU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_features = ['sex', 'age_approx'] + [col for col in train_df.columns if 'site_' in col]\n",
        "meta_features.remove('anatom_site_general_challenge')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:09:24.734306Z",
          "iopub.execute_input": "2022-06-17T04:09:24.734691Z",
          "iopub.status.idle": "2022-06-17T04:09:24.740512Z",
          "shell.execute_reply.started": "2022-06-17T04:09:24.734659Z",
          "shell.execute_reply": "2022-06-17T04:09:24.739300Z"
        },
        "trusted": true,
        "id": "Nfr5nEDqCFFU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = MelanomaDataset(df=test_df,\n",
        "                       imfolder=home+'melanoma-external-malignant-256/test/test/', \n",
        "                       train=False,\n",
        "                       transforms=train_transform,  # For TTA\n",
        "                       meta_features=meta_features)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:09:25.561885Z",
          "iopub.execute_input": "2022-06-17T04:09:25.562325Z",
          "iopub.status.idle": "2022-06-17T04:09:25.568490Z",
          "shell.execute_reply.started": "2022-06-17T04:09:25.562295Z",
          "shell.execute_reply": "2022-06-17T04:09:25.566857Z"
        },
        "trusted": true,
        "id": "p7ZsZ1wUCFFV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = GroupKFold(n_splits=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:09:27.046132Z",
          "iopub.execute_input": "2022-06-17T04:09:27.046539Z",
          "iopub.status.idle": "2022-06-17T04:09:27.051848Z",
          "shell.execute_reply.started": "2022-06-17T04:09:27.046507Z",
          "shell.execute_reply": "2022-06-17T04:09:27.050452Z"
        },
        "trusted": true,
        "id": "jY_GE4INCFFV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 12  # Number of epochs to run\n",
        "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
        "TTA = 3 # Test Time Augmentation rounds\n",
        "\n",
        "oof = np.zeros((len(train_df), 1))  # Out Of Fold predictions\n",
        "preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device)  # Predictions for test test\n",
        "\n",
        "skf = KFold(n_splits=5, shuffle=True, random_state=47)\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=train_df['patient_id'].tolist()), 1):\n",
        "    print('=' * 20, 'Fold', fold, '=' * 20)  \n",
        "    \n",
        "    model_path = f'model_{fold}.pth'  # Path and filename to save model to\n",
        "    best_val = 0  # Best validation score within this fold\n",
        "    patience = es_patience  # Current patience counter\n",
        "    arch = EfficientNet.from_pretrained('efficientnet-b1')\n",
        "    model = Net(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n",
        "    model = model.to(device)\n",
        "    \n",
        "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.2)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    train = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True), \n",
        "                            imfolder=home+'melanoma-external-malignant-256/train/train/', \n",
        "                            train=True, \n",
        "                            transforms=train_transform,\n",
        "                            meta_features=meta_features)\n",
        "    val = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True), \n",
        "                            imfolder=home+'melanoma-external-malignant-256/train/train/', \n",
        "                            train=True, \n",
        "                            transforms=test_transform,\n",
        "                            meta_features=meta_features)\n",
        "    \n",
        "    train_loader = DataLoader(dataset=train, batch_size=64, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(dataset=val, batch_size=16, shuffle=False, num_workers=2)\n",
        "    test_loader = DataLoader(dataset=test, batch_size=16, shuffle=False, num_workers=2)\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        correct = 0\n",
        "        epoch_loss = 0\n",
        "        model.train()\n",
        "        \n",
        "        for x, y in train_loader:\n",
        "            x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n",
        "            x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
        "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
        "            optim.zero_grad()\n",
        "            z = model(x)\n",
        "            loss = criterion(z, y.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
        "            correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
        "            epoch_loss += loss.item()\n",
        "        train_acc = correct / len(train_idx)\n",
        "        \n",
        "        model.eval()  # switch model to the evaluation mode\n",
        "        val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
        "        with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
        "            # Predicting on validation set\n",
        "            for j, (x_val, y_val) in enumerate(val_loader):\n",
        "                x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
        "                x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
        "                y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
        "                z_val = model(x_val)\n",
        "                val_pred = torch.sigmoid(z_val)\n",
        "                val_preds[j*val_loader.batch_size:j*val_loader.batch_size + x_val[0].shape[0]] = val_pred\n",
        "            val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
        "            val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
        "            \n",
        "            print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
        "            epoch + 1, \n",
        "            epoch_loss, \n",
        "            train_acc, \n",
        "            val_acc, \n",
        "            val_roc, \n",
        "            str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
        "            \n",
        "            scheduler.step(val_roc)\n",
        "                \n",
        "            if val_roc >= best_val:\n",
        "                best_val = val_roc\n",
        "                patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
        "                torch.save(model, model_path)  # Saving current best model\n",
        "            else:\n",
        "                patience -= 1\n",
        "                if patience == 0:\n",
        "                    print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
        "                    break\n",
        "                \n",
        "    model = torch.load(model_path)  # Loading best model of this fold\n",
        "    model.eval()  # switch model to the evaluation mode\n",
        "    val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
        "    with torch.no_grad():\n",
        "        # Predicting on validation set once again to obtain data for OOF\n",
        "        for j, (x_val, y_val) in enumerate(val_loader):\n",
        "            x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
        "            x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
        "            y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
        "            z_val = model(x_val)\n",
        "            val_pred = torch.sigmoid(z_val)\n",
        "            val_preds[j*val_loader.batch_size:j*val_loader.batch_size + x_val[0].shape[0]] = val_pred\n",
        "        oof[val_idx] = val_preds.cpu().numpy()\n",
        "        \n",
        "        # Predicting on test set\n",
        "        tta_preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device)\n",
        "        for _ in range(TTA):\n",
        "            for i, x_test in enumerate(test_loader):\n",
        "                x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n",
        "                x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n",
        "                z_test = model(x_test)\n",
        "                z_test = torch.sigmoid(z_test)\n",
        "                tta_preds[i*test_loader.batch_size:i*test_loader.batch_size + x_test[0].shape[0]] += z_test\n",
        "        preds += tta_preds / TTA\n",
        "    \n",
        "preds /= skf.n_splits"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:10:14.147327Z",
          "iopub.execute_input": "2022-06-17T04:10:14.147695Z",
          "iopub.status.idle": "2022-06-17T04:55:32.367652Z",
          "shell.execute_reply.started": "2022-06-17T04:10:14.147665Z",
          "shell.execute_reply": "2022-06-17T04:55:32.364112Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWuNNE36CFFV",
        "outputId": "d595c9e6-86e5-4fcc-a3b6-8c99429999c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Fold 1 ====================\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "Epoch 001: | Loss: 36.284 | Train acc: 0.981 | Val acc: 0.984 | Val roc_auc: 0.810 | Training time: 0:06:17\n",
            "Epoch 002: | Loss: 32.785 | Train acc: 0.982 | Val acc: 0.984 | Val roc_auc: 0.764 | Training time: 0:06:16\n",
            "Epoch 003: | Loss: 32.061 | Train acc: 0.982 | Val acc: 0.984 | Val roc_auc: 0.874 | Training time: 0:06:15\n",
            "Epoch 004: | Loss: 31.420 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.887 | Training time: 0:06:16\n",
            "Epoch 005: | Loss: 30.821 | Train acc: 0.982 | Val acc: 0.984 | Val roc_auc: 0.851 | Training time: 0:06:16\n",
            "Epoch 006: | Loss: 30.580 | Train acc: 0.982 | Val acc: 0.982 | Val roc_auc: 0.885 | Training time: 0:06:16\n",
            "Epoch 00006: reducing learning rate of group 0 to 2.0000e-04.\n",
            "Epoch 007: | Loss: 27.977 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.890 | Training time: 0:06:16\n",
            "Epoch 008: | Loss: 26.704 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.881 | Training time: 0:06:16\n",
            "Epoch 009: | Loss: 26.210 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.878 | Training time: 0:06:16\n",
            "Epoch 00009: reducing learning rate of group 0 to 4.0000e-05.\n",
            "Epoch 010: | Loss: 24.205 | Train acc: 0.982 | Val acc: 0.982 | Val roc_auc: 0.879 | Training time: 0:06:16\n",
            "Early stopping. Best Val roc_auc: 0.890\n",
            "==================== Fold 2 ====================\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "Epoch 001: | Loss: 37.172 | Train acc: 0.980 | Val acc: 0.984 | Val roc_auc: 0.753 | Training time: 0:06:19\n",
            "Epoch 002: | Loss: 31.825 | Train acc: 0.982 | Val acc: 0.984 | Val roc_auc: 0.861 | Training time: 0:06:18\n",
            "Epoch 003: | Loss: 31.232 | Train acc: 0.982 | Val acc: 0.984 | Val roc_auc: 0.857 | Training time: 0:06:18\n",
            "Epoch 004: | Loss: 30.814 | Train acc: 0.982 | Val acc: 0.984 | Val roc_auc: 0.843 | Training time: 0:06:18\n",
            "Epoch 00004: reducing learning rate of group 0 to 2.0000e-04.\n",
            "Epoch 005: | Loss: 28.161 | Train acc: 0.982 | Val acc: 0.984 | Val roc_auc: 0.889 | Training time: 0:06:18\n",
            "Epoch 006: | Loss: 26.806 | Train acc: 0.982 | Val acc: 0.984 | Val roc_auc: 0.899 | Training time: 0:06:18\n",
            "Epoch 007: | Loss: 25.943 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.902 | Training time: 0:06:18\n",
            "Epoch 008: | Loss: 25.518 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.907 | Training time: 0:06:18\n",
            "Epoch 009: | Loss: 24.315 | Train acc: 0.982 | Val acc: 0.981 | Val roc_auc: 0.843 | Training time: 0:06:18\n",
            "Epoch 010: | Loss: 23.520 | Train acc: 0.983 | Val acc: 0.983 | Val roc_auc: 0.893 | Training time: 0:06:18\n",
            "Epoch 00010: reducing learning rate of group 0 to 4.0000e-05.\n",
            "Epoch 011: | Loss: 20.600 | Train acc: 0.984 | Val acc: 0.983 | Val roc_auc: 0.897 | Training time: 0:06:18\n",
            "Early stopping. Best Val roc_auc: 0.907\n",
            "==================== Fold 3 ====================\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "Epoch 001: | Loss: 34.983 | Train acc: 0.981 | Val acc: 0.980 | Val roc_auc: 0.788 | Training time: 0:06:18\n",
            "Epoch 002: | Loss: 30.994 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.777 | Training time: 0:06:18\n",
            "Epoch 003: | Loss: 30.505 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.855 | Training time: 0:06:18\n",
            "Epoch 004: | Loss: 29.852 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.841 | Training time: 0:06:18\n",
            "Epoch 005: | Loss: 29.810 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.876 | Training time: 0:06:18\n",
            "Epoch 006: | Loss: 29.397 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.891 | Training time: 0:06:18\n",
            "Epoch 007: | Loss: 28.557 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.862 | Training time: 0:06:18\n",
            "Epoch 008: | Loss: 27.968 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.854 | Training time: 0:06:18\n",
            "Epoch 00008: reducing learning rate of group 0 to 2.0000e-04.\n",
            "Epoch 009: | Loss: 26.374 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.908 | Training time: 0:06:18\n",
            "Epoch 010: | Loss: 24.748 | Train acc: 0.983 | Val acc: 0.979 | Val roc_auc: 0.911 | Training time: 0:06:18\n",
            "Epoch 011: | Loss: 24.141 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.915 | Training time: 0:06:19\n",
            "Epoch 012: | Loss: 23.124 | Train acc: 0.983 | Val acc: 0.980 | Val roc_auc: 0.904 | Training time: 0:06:18\n",
            "==================== Fold 4 ====================\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "Epoch 001: | Loss: 37.080 | Train acc: 0.981 | Val acc: 0.983 | Val roc_auc: 0.635 | Training time: 0:06:18\n",
            "Epoch 002: | Loss: 31.461 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.820 | Training time: 0:06:19\n",
            "Epoch 003: | Loss: 31.357 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.850 | Training time: 0:06:19\n",
            "Epoch 004: | Loss: 30.752 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.847 | Training time: 0:06:19\n",
            "Epoch 005: | Loss: 30.764 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.859 | Training time: 0:06:19\n",
            "Epoch 006: | Loss: 30.595 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.849 | Training time: 0:06:19\n",
            "Epoch 007: | Loss: 30.346 | Train acc: 0.982 | Val acc: 0.982 | Val roc_auc: 0.835 | Training time: 0:06:18\n",
            "Epoch 00007: reducing learning rate of group 0 to 2.0000e-04.\n",
            "Epoch 008: | Loss: 28.672 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.876 | Training time: 0:06:18\n",
            "Epoch 009: | Loss: 27.559 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.885 | Training time: 0:06:19\n",
            "Epoch 010: | Loss: 26.681 | Train acc: 0.982 | Val acc: 0.982 | Val roc_auc: 0.891 | Training time: 0:06:18\n",
            "Epoch 011: | Loss: 27.149 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.894 | Training time: 0:06:19\n",
            "Epoch 012: | Loss: 26.369 | Train acc: 0.982 | Val acc: 0.983 | Val roc_auc: 0.898 | Training time: 0:06:18\n",
            "==================== Fold 5 ====================\n",
            "Loaded pretrained weights for efficientnet-b1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('OOF: {:.3f}'.format(roc_auc_score(train_df['target'], oof)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:55:32.370483Z",
          "iopub.status.idle": "2022-06-17T04:55:32.371205Z"
        },
        "trusted": true,
        "id": "ydNc0UOFCFFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(pd.Series(preds.cpu().numpy().reshape(-1,)));"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:55:32.373072Z",
          "iopub.status.idle": "2022-06-17T04:55:32.374119Z"
        },
        "trusted": true,
        "id": "axnOpGjlCFFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving OOF predictions so stacking would be easier\n",
        "pd.Series(oof.reshape(-1,)).to_csv('oof.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:55:32.376099Z",
          "iopub.status.idle": "2022-06-17T04:55:32.377030Z"
        },
        "trusted": true,
        "id": "9lJGtu2kCFFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv(home+'sample_submission.csv')\n",
        "sub['target'] = preds.cpu().numpy().reshape(-1,)\n",
        "sub.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-17T04:55:32.378813Z",
          "iopub.status.idle": "2022-06-17T04:55:32.379834Z"
        },
        "trusted": true,
        "id": "i4imBlwcCFFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lSNlihogW2Fl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}